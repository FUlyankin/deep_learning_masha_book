# 7. Картинки с потерями

::::{important}
Задачка не доделана. Я хочу собрать разных динамик функций потерь и посрашивать о том, что происходит на графиках. Оказалось, что сгенерировать подходящие данные сложновато. 
::::


Маша обучает нейросеть. На каждой эпохе она замеряет качество нейросети на обучающей и валидационной выборках и рисует картинки с динамикой качества модели. По оси абсцисс откладывается номер эпохи, по оси ординат откладывается значение функции потерь. 

__а)__ Во время обучения маша увидела следующие динамику потерь. Что означает такая динамика? Что Маше следует сделать? 

<img src="../images/problem_set_04/img07_loss_01.png" alt="dobronet_forward" width="95%" align="center">

```{dropdown} Решение

Нормализация данных 

```

__б)__ А что означает такая динамика? Что можно сделать, что с нейросеткой всё стало хорошо? 

<img src="../images/problem_set_04/img07_loss_02.png" alt="dobronet_forward" width="95%" align="center">


```{dropdown} Решение

Переобучение + рання остановка

```

__в)__ А теперь? 



```{dropdown} Решение

Забыли перемешеть 

```

__г)__ А тут? 

```{dropdown} Решение

Взрыв градиента

```

__д)__ А теперь? 

```{dropdown} Решение

Толи затухание толи доучились толи еще что .... 

```

__е)__ Маша Н. и Дима В. ...

```{dropdown} Решение

двойной спуск

```

__ё)__ Дима рассказал Маше как вчера обучал модель. Дима решал задачу бинарной классификации и обучал модель на логистические потери, logloss. Параллельно Дима наблюдал за тем, как ведёт себя доля правильных ответов, accuracy. 

На обучающей выборке accuracy и logloss всё время улучшались. На тесте, начиная с какой-то эпохи, logloss начал ухудшаться, но accuracy, при этом, продолжил улучшаться. Может ли такой быть или Дима врёт? Если да, почему это произошло и как можно это починить? 


```{dropdown} Решение


```

::::{important}
Хочется придумать примеров, где мы оптимизируем какую-то функцию потерь, а качество измеряем по ортогональной метрике и всё ломается. 
::::









