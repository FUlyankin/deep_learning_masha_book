# 5. Скорости обучения*

В стохастическом градиентном спуске веса изменяются по формуле

$$
w_t = w_{t-1} - \eta_t \cdot \nabla_w L(w_{t-1}, x_i, y_i),
$$ 

где наблюдение $i$ выбрано случайно, скорость обучения зависит от номера итерации. 

Условия Роббинса-Монро гарантируют сходимость алгоритма к оптимуму для выпуклых дифференцируемых функций. Они говорят, что ряд из скоростей $\sum_{t=0}^{\infty} \eta_t$ должен расходиться, а ряд $\sum_{t=0}^{\infty} \eta_t^2$ сходиться. 

То есть скорость спуска должна падать не слишком медленно, но и не слишком быстро. Какие из последовательностей, перечисленных ниже, можно использовать для описания изменения скорости алгоритма? 


::::{important}
Это чисто техническое упражнение, которое можно пропустить. К сожалению, в глубоком обучении нам доводится редко встречаться с выпуклыми функциями потерь $L(w).$ Поэтому мы используем всё, что работает. Никаких теоретических гарантий нет.

Ландшафт функции потерь для нейронных сетей устроен довольно сложно. Вокруг него возникает довольно много интересных казусов. Посмотреть о них подробнее можно [в открытой лекции Дмитрия Ветрова](https://www.youtube.com/watch?v=SKYXBPCJHCg) и [её продолжении.](https://www.youtube.com/watch?v=7bvvLzm-Tb0) Про исследования ландшафта функций потерь можно подробнее почитать [по ссылке.](https://losslandscape.com/)
::::


__а)__ $\eta_t = \frac{1}{t}$

```{dropdown} Решение
Ряд не сходится (следует из интегрального признака Коши). Обобщенный гармонический ряд $\sum 1/n^{p} $ сходится при $ p > 1$ и расходится при $p \le 1$. Ряд $\eta_t^2 = \frac{1}{t^2}$ сходится. Значит такая величина шага нам подходит.

::::{important}
Читатель мог подумать примерно следующее. Чего? Какие нахрен ряды? Какие сходимости? Какие признаки? Нифига непонятно, я не помню матан. Но очень хочетс понять...

Я могу порекомендовать почитать [серию статей с mathprofi](http://www.mathprofi.ru/ryady_dlya_chajnikov.html) либо забить на эту задачу.
::::

```

__б)__ $\eta_t = \frac{0.1}{t^{0.3}}$

```{dropdown} Решение
Не подойдет. Ни сам ряд, ни его квадрат не сходятся по интегральному признаку Коши. 
```

__в)__ $\eta_t = \frac{1}{\sqrt{t}}$

```{dropdown} Решение
Не подойдет. Ни сам ряд, ни его квадрат не сходятся по интегральному признаку Коши.
```

__г)__ $\eta_t = \frac{1}{t^2}$

```{dropdown} Решение
Не подойдет. Оба ряда сходятся по интегральному признаку Коши. 
```

__д)__ $\eta_t = e^{-t}$

```{dropdown} Решение
Используем признак Даламбера
	
$$
\left| \frac{e^{-t-1}}{e^{-t}} \right| = \left| \frac{e^{-t}}{e^{-t}} \cdot \frac{1}{e} \right|  = \left| \frac{1}{e} \right| < 1.
$$
    	
Получается, что ряд сходится. Такая скорость нам не подходит. 
```

__е)__ $\eta_t = \lambda \cdot \left(\frac{s_0}{s_0 + t} \right)^p,$ где $\lambda, p$ и $s_0$ --- параметры

```{dropdown} Решение
Надо аккуратненько через интегральный признак Коши проанализировать какие параметры подойдут. 
```
