# 6. Число параметров

На вход в нейронную сетку идёт изображение рукописной цифры размера $28 \times 28$.


__а)__ Маша вытягивает изображение в длинный вектор и использует полносвязную сетку для классификации изображений. В сетке идёт один полносвязный слой из $1000$ нейронов. После идёт слой, который осуществляет классификацию изображения на $10$ классов. Сколько параметров нужно оценить?

```{dropdown} Решение
На вход в нейросетку идёт $28 \cdot 28 = 784$ переменные. На первом слое мы будем обучать $1000$ свободных членов и $784 000$ коэффициентов. 

На втором слое мы будем обучать $1000 \cdot 10 + 10$ параметров. На выходе, к $10$ получившимся числам, мы будем применять Softmax и получать вероятности. 

Итоговое количество параметров будет

$$
784 \cdot 1000 + 1000 + 1000 \cdot 10 + 10 = 795010.
$$ 

```

__б)__ Маша вместо полносвязной сетки использует свёрточную. На первом шаге делается $6$ свёрток размера $5 \times 5$. На втором шаге делается max-pooling размера $2 \times 2$. На третьем $16$ свёрток размера $5\times 5$. На четвёртом max-pooling размера $2 \times 2$. На пятом картинка вытягивается в длинный вектор. Далее идут три полносвязных слоя размеров $120, 84, 10$. В конце делается softmax. После каждой свёртки и полносвязного слоя, кроме последнего, в качестве функции активации используется $ReLU.$ 

```{figure} ../images/problem_set_06/img06_nn.png
---
width: 650px
name: regression
---
```

Какого размера будут выходы из каждого слоя?  Сколько параметров необходимо будет оценить в такой модели? 

```{dropdown} Решение
Определимся с размерами выхода каждого слоя:

- размер входа $28 \times 28$
- после первой свёртки $(28 - 4) \times (28 - 4) \times 6 = 24 \times 24 \times 6$
- после пулинга $(24/2) \times (24/2) \times 6 = 12 \times 12 \times 6$
- после второй свёртки $(12-4) \times (12-4) \times 16 = 8 \times 8 \times 16$
- после пулинга $(8/2) \times (8/2) \times 16 = 4 \times 4 \times 16$
- после вытягивания получаем вектор $4 \cdot 4 \cdot 16 = 256$
- после полносвязного слоя размер выхода будет $120$
- после второго полносвязного слоя размер выхода будет $84$
- после третьего полносвязного словя размер выхода будет $10$
- после применения softmax рамзер выхода не изменится

Если у нас чёрно-белая картинка $Image$ и мы применяем к ней свёртку $K$ размера $k \times k$, тогда на выходе мы будем получать клетки нового изображения по формуле

$$
out[x, y] = \sum_{i = -k}^{k}  \sum_{j = -k}^{k}   K[i, j] \cdot Image[x + i, y + j].
$$

Если у изображения несколько каналов, к каждому из них мы применяем одну и те же веса, а затем делаем по ним суммирование

$$
out[x, y] = \sum_{i = -k}^{k}  \sum_{j = -k}^{k}  \sum_{c= 1}^{C}  K[i, j] \cdot Image[x + i, y + j, c]
$$

Также можно использовать ядра с дополнительной размерностью по числу каналов. Так можно поступать с цветными изображениями либо с фичами, которые получаются внутри сети после применения нескольких свёрток. Давайте посчитаем для нашей нейросети количество параметров для ситуации, когда мы используем для каждого канала одну и ту же свёртку.

Например, у нас на первом слое к картинке применяется $6$ свёрток размера $5 \times 5$ и на выходе у нас получается параллелепипед из циферок. К нему мы будем применять именно второй вариант свёртки.

Подсчитаем число параметров, которые нам надо оценить, для каждого слоя: 

- для первой свёртки это $(5 \cdot 5 + 1) \cdot 6 = 156$ весов
- у пулинга нет параметров, мы просто выбираем максимум из квадратиков размера $2 \times 2$.
- для второй свёртки это $(5 \cdot 5 + 1) \cdot 16 = 416$
- у пулинга снова нет параметров 
- у вытягивания нет параметров
- у полносвязных слоев окажется

$$
256 \cdot 120 + 120 + 120 \cdot 84 + 84 + 84 \cdot 10 + 10 = 41854
$$

Итоговое количество параметров будет 

$$
41854 + 416 + 156 = 42426.
$$

При этом, нейросеть покажет на порядок лучшее качество, чем полносвязная. 

```

__в)__ Маша использует архитектуру из предыдущего пункта, но все свёртки делает с дополнением нулями (zero padding). Как изменится число оцениваемых параметров? Какого размера будут выходы из каждого слоя? 

```{dropdown} Решение
Определимся с размерами выхода каждого слоя:

- размер входа $28 \times 28$
- после первой свёртки $28 \times 28 \times 6$
- после пулинга $(28/2) \times (28/2) \times 6 = 14 \times 14 \times 6$
- после второй свёртки $14 \times 14 \times 16$
- после пулинга $(14/2) \times (14/2) \times 16 = 7 \times 7 \times 16$
- после вытягивания получаем вектор $7 \cdot 7 \cdot 16 = 784$
- после полносвязного слоя размер выхода будет $120$
- после второго полносвязного слоя размер выхода будет $84$
- после третьего полносвязного словя размер выхода будет $10$
- после применения softmax рамзер выхода не изменится

Число параметров, которое нам надо оценить на свёрточных слоях, не изменится

$$
156 + 416 = 572.
$$

Для полносвязных слоёв количество параметров будет другим, так как выход из последнего свёрточного слоя изменил размерность 

$$
784 \cdot 120 + 120 + 120 \cdot 84 + 84 + 84 \cdot 10 + 10 = 105214
$$

Итого получаем $105786$ параметров.

```

__г)__ Маша использует ту же самую архитектуру, но все свёртки делает с параметром сдвига (stride) равным $2$. Как изменится число оцениваемых параметров? Какого размера будут выходы из каждого слоя?

```{dropdown} Решение
Разберемся с размерами выходов из каждого слоя:

- размер после свёртки $(28 - 4)/2 \times (28 - 4)/2 \times 6 = 12 \times 12 \times 6$
- после пулинга получаем $12/2 \times 12/2 \times 6 = 6 \times 6 \times 6$
- после свёртки получаем $(6-4)/2  \times (6-4)/2 \times 16 = 1 \times 1 \times 16$
- на пулинге модель разваливается, так как мы слишком мощно понижали размерность картинки и пулингу нечего будет сокращать.
```










