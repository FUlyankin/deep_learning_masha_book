# 7. Жесткая и бесполезная задача про инициализацию*

У Маши есть линейный слой без функции активации $H = XW + b$. Маша хочет, чтобы у выхода из этого линейного слоя было нормальное распределение, $h_{ij} \sim N(0, \sigma^2).$ Пусть наблюдения и признаки независимы друг от друга.

__а)__  Пусть $x_{ij} \sim N(0, 1)$. Какое распределение можно использовать для инициализации $W$ и $b$? 

```{dropdown} Решение
Посмотрим на один из выходов линейного слоя и проанализируем его 

$$
h_{11} = x_{11} w_{11} + x_{12} w_{21} + \ldots + x_{1k} w_{k1} + b_1.
$$

Будем считать, что веса инициализируются независимо от данных, поэтому случайные величины $x_{i}$ и $w{jk}$ независимы друг от друга. Будем генерировать веса независимо друг от друга. Тогда

\begin{multline*}
	\mathbb{E}(h_{11}) = \mathbb{E}(x_{11} w_{11} + x_{12} w_{21} + \ldots + x_{1k} w_{k1} + b_1) = \\ = \mathbb{E}(x_{11} w_{11}) + \mathbb{E}(x_{12} w_{21}) + \ldots + \mathbb{E}(x_{1k} w_{k1}) + \mathbb{E}(b_1) = \\ = \mathbb{E}(x_{11}) \cdot \mathbb{E}(w_{11}) + \mathbb{E}(x_{12}) \cdot \mathbb{E}(w_{21}) + \ldots + \mathbb{E}(x_{1k}) \cdot \mathbb{E}(w_{k1}) + \mathbb{E}(b_1) = 0
\end{multline*}

Все $\mathbb{E}(x_{ij}) = 0$, значит математическое ожидание весов может быть любым. Математическое ожидание $\mathbb{E}(b_1)$ надо сделать нулевым. Посмотрим на дисперсию

\begin{multline*}
	\text{Var}(h_{11}) = \text{Var}(x_{11} w_{11} + x_{12} w_{21} + \ldots + x_{1k} w_{k1} + b_1) = \\ = \text{Var}(x_{11} w_{11}) + \text{Var}(x_{12} w_{21}) + \ldots + \text{Var}(x_{1k} w_{k1}) + \text{Var}(b_1) = \\ = \text{Var}(x_{11}) \cdot \text{Var}(w_{11}) + \text{Var}(x_{12}) \cdot \text{Var}(w_{21}) + \ldots + \text{Var}(x_{1k}) \cdot \text{Var}(w_{k1}) + \text{Var}(b_1) = \\ = 1 \cdot s + 1 \cdot s + \ldots + 1\ cdot s + s = \sigma^2.
\end{multline*}

Получается, что $$s = \frac{\sigma^2}{k + 1}.$$

Мы хотим, чтобы итоговое распределение оказалось нормальным. Для этого распределение каждого слагаемого должно быть нормальным. Можно инициализировать параметр $b$ как $b \sim N \left(0, \frac{\sigma^2}{k + 1} \right).$ Для весов $w$ нормальное распределение не подойдёт, так как в таком случае мы будем умножать дург на друга два нормальных распределения и на выходе получим распределение из совершенно другого семейства. 

Нормальное распределение можно сохранить, если инициализировать веса из распределения Бернулли, $w_{jk} \sim Bern(p)$. В таком случае часть нормальных распределений занулится, часть останется, но в итоге мы всегда получим сумму из нормальных. 

Нам надо проконтролировать дисперсию

$$
\text{Var}(w_{jk}) = p \cdot (1 - p) = \frac{\sigma^2}{k + 1}.
$$

Выходит, что 

$$
p^2 - p + \frac{\sigma^2}{k + 1} = 0.
$$

Отсюда получаем два корня 

$$
p_{1,2} = 0.5 \cdot (1 \pm \sqrt{1 - 4 \sigma^2/(k + 1)}).
$$

У нас нет никаких гарантий, чтобы $0 \le p \le 1.$ Было бы хорошо перетащить всю дисперсию в $b$, а для $w_{jk}$ выбрать более нейтральное распределение. Пусть $w_{jk}$ принимает значения $1$ и $-1$ с вероятностями $0.5$. Тогда $\mathbb{E}(w_{jk}) = 0, \text{Var}(w_{jk}) = 0.25.$ 

Получаетcя, что $\text{Var}(h_1) = \frac{k}{4} + s = \sigma^2.$ Отсюда получаем, что параметр $b$ надо инициализировать как 

$$
b \sim N \left(0, \sigma^2 - \frac{k}{4} \right).
$$

```


__б)__ Пусть $x_{ij} \sim U[0; a].$ Какое распределение можно использовать для инициализации $W$ и $b$? 


```{dropdown} Решение
Поднимаем уровень сложности и бесполезности. Вспомним, что для равномерного распределения 

$$
\mathbb{E}(x_{ij}) = \frac{a}{2} \quad \text{Var}(x_{ij}) = \frac{a^2}{12}.
$$

Посмотрим на математическое ожидание и дисперсию нашего выхлопа

$$
\mathbb{E}(h_i) = \frac{a}{2} \cdot \mathbb{E}(w_{11}) + \frac{a}{2} \cdot \mathbb{E}(w_{21}) + \ldots + \frac{a}{2} \cdot \mathbb{E}(w_{k1}) + \mathbb{E}(b_1) = 0.
$$

Отсюда получаем, что нам надо, чтобы $\mathbb{E}(w_{jk}) = 0$ и $\mathbb{E}(b_k) = 0$.

Посмотрим на дисперсию

$$
\text{Var}(h_i) = \frac{a^2}{12} \cdot \text{Var}(w_{11}) + \frac{a^2}{12}  \cdot \text{Var}(w_{21}) + \ldots + \frac{a^2}{12}  \cdot \text{Var}(w_{k1}) + \text{Var}(b_1) = \sigma^2.
$$

То есть 

$$
\frac{a^2}{12} \cdot k \cdot s_w + s_b = \sigma^2.
$$

Нам нужно, чтобы каждое произведение $x_{ij} \cdot w_{jk}$ было нормально распределено. Наблюдения распределены равномерно. Нам надо выбрать распределение весов так, чтобы произведение дало нам  нормальное распределение. 

Давайте найдём плотность этого распределения. Из курса по теории вероятностей можно вспомнить формулу для плотности распределения частного [^gnedenko].

Если у нас есть две независимые случайные величины $Z$ и $Y$ и нам надо найти распределение $X = \frac{Z}{Y},$ мы можем сделать это по формуле 

$$
f_X(x) = \int_0^{+\infty} z f_Z(zx) \cdot f_Y(z) dz - \int_{-\infty}^{0} z f_Z(zx) \cdot f_Y(z) dz.
$$

Второе слагаемое в нашем случае зануляется, так как для равномерного распределения 

$$
f_Y(y) = \begin{cases} \frac{1}{a}, y \in [0; a] \\ 0, \text{ иначе}.
$$

Получается

\begin{multline*}
f_X(x) =\int_0^{a} z \cdot \frac{1}{\sqrt{2 \pi}} \cdot e^{- \dfrac{z^2 \cdot x^2}{2}} \cdot \frac{1}{a} dz = \\ = \frac{1}{a \cdot \sqrt{2 \pi}}  \cdot \int_0^{a} z \cdot \cdot e^{- \dfrac{z^2 \cdot x^2}{2}} dz = \\ = \frac{1}{a \cdot \sqrt{2 \pi}}  \cdot \frac{1}{x^2} \cdot (1 - e^{- \dfrac{(ax)^2}{2}}).
\end{multline*}

Для взятия интеграла мы воспользовались интегрированием по частям. Получается, что плотность нашего распределения должна иметь вид 

$$
f_w(x) = \frac{1}{a \cdot \sqrt{2 \pi}}  \cdot \frac{1}{x^2} \cdot (1 - e^{- \dfrac{(ax)^2}{2}}), \quad x \in (-\infty, +\infty).
$$

Тогда $x_{ij} \cdot w_{jk} \sim N(0, 1),$ а константу можно инициализировать как $b \sim N(0, \sigma^2 - k).$

```

[^gnedenko]: Выведение этой формулы можно посмотреть в [учебнике по теории вероятностей Гнеденко](https://nmetau.edu.ua/file/gnedenko1988.pdf) на странице 143.
